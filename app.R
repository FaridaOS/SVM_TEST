library(e1071)
library(kernlab)  
library(lattice)
library(ggplot2)
library(caret) 
library(plotROC) 
library(tidyverse)   
library(shiny)  
library(dashboard) 
library(shinythemes)

h3.align <- 'center'

coc=navbarPage( 
  
 title = "Dectection de la fraude par les svm", 
  theme = shinytheme("cyborg"),
  shinythemes::themeSelector(),
    tabPanel(
       title= " Description des donnees",  
         sidebarLayout(  
             sidebarPanel(   
               
                sliderInput("N",label= "Taille de lechantillon", value=10000,min=2000,max=40000), 
                #checkboxGroupInput("TG", label = "TYPE de Graphique:",c("Line_plot","Histogram"),selected="Histogram"),
                sliderInput("d",label= "Representer A partir de la:", value=9,min=1,max=22)
                      ), 
           mainPanel( 
             tabsetPanel( 
               tabPanel(p(icon("bar-chart-o"),"Graphique") ,plotOutput("G_descript")), 
               tabPanel(p(icon("table"),"donnees"),tableOutput("donnee")), 
               tabPanel(p(icon("table"),"Correlations matrix"),tableOutput("corr")), 
               tabPanel(p(icon("area-chart"),"scatterplot"),plotOutput("scatter")),
               selected="Graphique",id='Graphique',type="pills"
              
            ) 
          )#ferme mainpanel
         ) #ferme sidebarlayout
      ) ,#ferme tabpanel 
    
   tabPanel( 
     title=" Modelisation",  
        sidebarLayout(  
            sidebarPanel(width = 3, 
               sliderInput("degree",label= "degree du polynome", value=2,min=1,max=3), 
               sliderInput("coef",label= "Coefficient du kernel", value=1,min=0,max=3)
            ), 
      
      mainPanel( 
        tabsetPanel( 
          tabPanel(p(icon("area-chart"),"Taux linear"),plotOutput("linear")), 
          tabPanel(p(icon("area-chart"),"taux polynomial"),plotOutput("poly")), 
          tabPanel(p(icon("area-chart"),"taux sigmoid"),plotOutput("sigmoid")),   
          
          
          tabPanel(p(icon("area-chart"),"performance"),
                   fluidRow(h3("Analyse comparative des kernels", align=h3.align)),
                   fluidRow(
                     column(4, h4("anlayse par les courbes AUC", align="center"),
                            h6("le meileur kernel est celui ayant l AUC la plus extreme", align="center"),
                            plotOutput("perform")
                     ),
                     column(5, h4("Table anlyse par les matrices de confusions", align="center"),
                            h6("Plus pertinant etant donne que le taux de fraude est faible", align="center"),
                            renderTable("confusion"))
                     
                   )#ferme fluidrow 
                   
          ),#ferme tabpanel
          
      ##################################### 
          tabPanel(p(icon("bar-chart-o"),"analyse"),
            fluidRow(h3("benchmark du svm", align=h3.align)),
             fluidRow(
               column(7, h4("Nous retenons le kernel radial su svm", align="center"),
                 h6("sur la base des AUC", align="center"),
                 plotOutput("salesByStateOut")
                   ),
                column(5, h4("Gradient Boosting comme benchmar", align="center"),
                 h6("Considerer comme  le meilleur des machine learning", align="center"),
                 plotOutput("salesByLocOut"))
        
               )#ferme fluidrow 
        
            )#ferme tabpanel
          
          )#tabsetpanel
         ) #mainpanel 
       )#sidebarlayout
      )#tabpanel de la fenetre 
  )#navbarpage
        
#=================================Partie serveur======================================================= 

entre=function(input, output){ 
  
    output$G_descript=renderPlot({  
        
           #input pour le N
           N=input$N 
           d=input$d
           
           OBS=1:nrow(DONNEE)   
           Time=scale(as.numeric(DONNEE$Time),center=T,scale=T) 
           DONNEE$Time=Time 
           data_base=data.frame(OBS,DONNEE)
        
           #mes donnees avec tirage alealtoire de N observation
           train=sample(1:nrow(data_base),N) 
           data=data_base[train,-1]
           attach(data)   
        
           #creation des graphiques de 9 variables a partir de la d ieme variable: min(d)=1,max(d)=22
           par(mfrow=c(3,3))  
       
           #input type distibution hist ou plot 
           for( i in 1:9){ 
          
                       hist(data[,i+d-1],col=c(i:d),prob=T,main=paste("distribution of",c(names(data)[d+i-1])),
                      ylab="Frequence", xlab= names(data)[d+i-1]) 
                     }  
         })   
      
    output$donnee=renderTable({ 
      
         d=input$d
         E_data=data[,d:(d+8)]
         
         for(j in 1:9){ 
                  names(E_data)[j]=paste("E_",c(names(data)[d+j-1])) 
                      }   
         
        #sortie Correlations
        # round(cor(E_data),3) 
         E_data[1:20,]
       })  
    
    output$corr=renderTable({  
         
        N=input$N 
        d=input$d
      
        OBS=1:nrow(DONNEE)   
        Time=scale(as.numeric(DONNEE$Time),center=T,scale=T) 
        DONNEE$Time=Time 
        data_base=data.frame(OBS,DONNEE)
      
        #mes donnees avec tirage alealtoire de N observation
        train=sample(1:nrow(data_base),N) 
        data=data_base[train,-1]
        attach(data)  
        round(cor(data),4) 
      }) 
    
    output$scatter=renderPlot({   
        N=input$N 
        d=input$d   
        
        
        OBS=1:nrow(DONNEE)   
        Time=scale(as.numeric(DONNEE$Time),center=T,scale=T) 
        DONNEE$Time=Time 
        data_base=data.frame(OBS,DONNEE)
    
        train=sample(1:nrow(data_base),N) 
        data=data_base[train,-1]
        attach(data)  
    
        plot(data[,2],data[,d],col=c(4,3))
      
      })
    #===========================MODELISATION==============================================# 

    
    output$linear=renderPlot({    
      N=input$N
      V=ceiling(0.3*N) 
      
      
      OBS=1:nrow(DONNEE)   
      Time=scale(as.numeric(DONNEE$Time),center=T,scale=T) 
      DONNEE$Time=Time 
      data_base=data.frame(OBS,DONNEE)
      
      
      #mes donnees avec tirage alealtoire de N observation pour lechantillon test
      train=sample(1:nrow(data_base),N)  
      
      #pour lechantillon de validation
      valid=sample(1:nrow(data_base),V) 
      
      # les 2 echantillons
      test=data_base[valid,-1]
      data=data_base[train,-1]
      
      attach(data)   
      attach(test) 
      
      #definition de la variable cible test 
      y=test$Class
      
      RSSl=vector() 
      
      library(e1071)
      for(i in 1:5){  
        M_linear=svm(data$Class~.,data=data,type="C",scale=F,kernel="linear",cost=i) 
        
        #prevision pour le model linear
        p_linear=predict(M_linear,test[,-31],decision.values = T) 
        
        #taux derreur de classification pour le model linear
        
        RSSl[i]= mean(y!=p_linear) 
        
      } 
      
      plot(RSSl,type="l",col=6,main="taux d'erreur du kernel linear")
      
    }) 
    
    output$poly=renderPlot({  
      N=input$N
      V=ceiling(0.3*N) 
      
      
      OBS=1:nrow(DONNEE)   
      Time=scale(as.numeric(DONNEE$Time),center=T,scale=T) 
      DONNEE$Time=Time 
      data_base=data.frame(OBS,DONNEE)
      
      
      #mes donnees avec tirage alealtoire de N observation pour lechantillon test
      train=sample(1:nrow(data_base),N)  
      
      #pour lechantillon de validation
      valid=sample(1:nrow(data_base),V) 
      
      # les 2 echantillons
      test=data_base[valid,-1]
      data=data_base[train,-1]
      
      attach(data)   
      attach(test) 
      
      #definition de la variable cible test 
      y=test$Class
      RSSp=vector() 
      
      library(e1071)
      for(i in 1:5){ 
        M_pol=svm(data$Class~.,data=data,type="C",scale=F,kernel="polynomial",coef0=0,  degree=2,cost=i)  
        
        p_pol=predict(M_pol,test[,-31],decision.values = T) 
        
        RSSp[i]=mean(y!=p_pol) 
      } 
      
      plot(RSSp,type="l",col=5,xlab="cost",main="taux d'erreur pour le kernel polynomial")
      
      
      }) 
    
    output$sigmoid=renderPlot({  
      
        
        N=input$N
        V=ceiling(0.3*N) 
        
        
        OBS=1:nrow(DONNEE)   
        Time=scale(as.numeric(DONNEE$Time),center=T,scale=T) 
        DONNEE$Time=Time 
        data_base=data.frame(OBS,DONNEE)
        
        
        #mes donnees avec tirage alealtoire de N observation pour lechantillon test
        train=sample(1:nrow(data_base),N)  
        
        #pour lechantillon de validation
        valid=sample(1:nrow(data_base),V) 
        
        # les 2 echantillons
        test=data_base[valid,-1]
        data=data_base[train,-1]
        
        attach(data)   
        attach(test) 
        
        #definition de la variable cible test 
        y=test$Class  
        RSSs=vector()
        
        for(i in 1:5){
          M_sig=svm(data$Class~.,data=data,type="C",scale=F,kernel="sigmoid",cost=i) 
          
          p_sig=predict(M_sig,test[,-31],decision.values = T)
          RSSs[i]=mean(y!=p_sig)
        } 
        
        plot(RSSs,type="l",main="taux d'erreur pour le kernel sigmoid",xlab="cost") 
        #library(plotly)
        #xa=1:5
        #plot=data.frame(x=xa,z=RSSs)
        
        #plot_ly(plot,x=~x,y=~z,type="scatter",mode="lines") 
        
      
      }) 
    
    
    output$perform=renderPlot({ 
      
      
      N=input$N
      V=ceiling(0.3*N)  
      
      #les input de la performance 
      deg=input$degree 
      co=input$coef
      
      
      OBS=1:nrow(DONNEE)   
      Time=scale(as.numeric(DONNEE$Time),center=T,scale=T) 
      DONNEE$Time=Time 
      data_base=data.frame(OBS,DONNEE)
      
      
      #mes donnees avec tirage alealtoire de N observation pour lechantillon test
      train=sample(1:nrow(data_base),N)  
      
      #pour lechantillon de validation
      valid=sample(1:nrow(data_base),V) 
      
      # les 2 echantillons
      test=data_base[valid,-1]
      data=data_base[train,-1]
      
      attach(data)   
      attach(test) 
      
      #les library 
      library(kernlab)  
      library(lattice)
      library(ggplot2)
      library(caret) 
      library(plotROC) 
      library(tidyverse) 
      
    
      mod.pol = ksvm(data$Class~.,data=data,kernel="polydot",kpar=list(degree=deg,scale=1,offset=1),C=co,prob.model = TRUE,type="C-svc")
      mod.rad = ksvm(data$Class~.,data=data,kernel="rbfdot",kpar=list(sigma=0.01),C=co,prob.model = TRUE,type="C-svc")
      mod.liner = ksvm(data$Class~.,data=data,kernel="vanilladot",C=co,prob.model = TRUE,type="C-svc") 
      
      
      prev.class.pol = predict(mod.pol,newdata=test[,-31])
      prev.class.rad = predict(mod.rad,newdata=test[,-31]) 
      prev.class.liner = predict(mod.liner,newdata=test[,-31])
      
      prev.prob.pol = predict(mod.pol,newdata=test[,-31],type="probabilities")
      prev.prob.rad = predict(mod.rad,newdata=test[,-31],type="probabilities") 
      prev.prob.liner = predict(mod.liner,newdata=test[,-31],type="probabilities")
     
      
     # prev.class = data.frame(pol=prev.class.pol,rad=prev.class.rad,obs=test$Class) 
      #prev.class %>% summarise_all(funs(err=mean(obs!= .))) %>% select(-obs_err) %>% round(3)  
      
      prev.prob = data.frame(pol=prev.prob.pol[,2],rad=prev.prob.rad[,2],liner=prev.prob.liner[,2],obs=test$Class) 
      df.roc = prev.prob %>% gather(key=Methode,value=score,pol,rad,liner)
    
      ggplot(df.roc)+aes(d=obs,m=score,color=Methode)+geom_roc()+theme_classic()+ ggtitle("Courbe ROC")
     # df.roc %>% group_by(Methode) %>% summarize(AUC=pROC::auc(obs,score))
      
         }) 

          
} 

shinyApp(ui=coc,server=entre)

